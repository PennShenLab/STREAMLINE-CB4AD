{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f703f6e1",
   "metadata": {},
   "source": [
    "# Process the feature importance values from STREAMLINE outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdabe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read the original feature importance values\n",
    "\n",
    "def readFI(data_path):\n",
    "    \n",
    "    # give the order of the algs\n",
    "    alg_13_list = np.array(['NB', 'EN', 'LR', 'DT', 'RF', 'GB', 'XGB', 'LGB', 'CGB', 'SVM', 'ANN', 'KNN', 'GP'])\n",
    "    FI_mean = []\n",
    "    \n",
    "    #Determine file extension of datasets in target folder:\n",
    "    file_count = 0\n",
    "    unique_datanames = []\n",
    "    for alg_name in alg_13_list:\n",
    "        for dataset_path in sorted(glob.glob(data_path+'/*'), key=os.path.getmtime):\n",
    "            dataset_path = str(dataset_path).replace('\\\\','/')    \n",
    "            #print('---------------------------------------------------------------------------------')\n",
    "            #print(dataset_path)\n",
    "            file_extension = dataset_path.split('/')[-1].split('.')[-1]\n",
    "            data_name = dataset_path.split('/')[-1].split('.')[0] #Save unique dataset names so that analysis is run only once if there is both a .txt and .csv version of dataset with same name.\n",
    "            if data_name==alg_name+'_FI':\n",
    "                if file_extension == 'txt' or file_extension == 'csv':\n",
    "                    if data_name not in unique_datanames:\n",
    "                        unique_datanames.append(data_name)\n",
    "                        df = pd.read_csv(dataset_path,na_values='NA',sep=',')\n",
    "                        fi_mean = []\n",
    "                        for i in range(0,df.shape[1]):\n",
    "                            fi_mean.append(df.iloc[:,i].mean()) # average of k-cv folds\n",
    "                        fi_mean = np.array(fi_mean)\n",
    "                        FI_mean.append(fi_mean)\n",
    "                        file_count += 1\n",
    "    FI = np.array(FI_mean)\n",
    "    ROIs = df.columns.values\n",
    "    ROI_name = []\n",
    "    for i in range(len(ROIs)):\n",
    "        ROI_name.append(ROIs[i].split('_')[1]+\"_\"+ROIs[i].split('_')[2])  # extract ROIs names\n",
    "        \n",
    "    if file_count == 0: #Check that there was at least 1 dataset\n",
    "        raise Exception(\"There must be at least one .txt or .csv dataset in data_path directory\")\n",
    "    return FI,ROI_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recaling methods\n",
    "\n",
    "def rescaleFI(FI,ROI_name,path):\n",
    "    \n",
    "    algs = np.array(['NB', 'EN', 'LR', 'DT', 'RF', 'GB', 'XGB', 'LGB', 'CGB', 'SVM', 'ANN', 'KNN', 'GP','SUM'])\n",
    "    \n",
    "    # Normarlization\n",
    "\n",
    "    FI_norm = np.empty((FI.shape[0],FI.shape[1]))\n",
    "    for i in range(0,FI.shape[0]):\n",
    "        for j in range(0,FI.shape[1]):\n",
    "            if (FI[i,j]<=0):\n",
    "                FI_norm[i,j]=0\n",
    "            else:\n",
    "                FI_norm[i,j] = FI[i,j]/np.max(FI[i,:])\n",
    "\n",
    "    df =  pd.DataFrame(FI)\n",
    "    df_n =  pd.DataFrame(FI_norm)\n",
    "\n",
    "    # Fraction\n",
    "    FI_sum = FI\n",
    "    FI_frac = np.empty((FI.shape[0],FI.shape[1]))\n",
    "    for i in range(0,FI.shape[0]):\n",
    "        for j in range(0,FI.shape[1]):\n",
    "            if (FI[i,j]<=0):\n",
    "                FI_sum[i,j]=0              # Let negative values zero first, and then calculate sum FI\n",
    "        for j in range(0,FI_sum.shape[1]):\n",
    "            if (np.sum(FI_sum[i,:])==0):\n",
    "                FI_frac[i,j]=0\n",
    "            else:\n",
    "                FI_frac[i,j] = FI_sum[i,j]/np.sum(FI_sum[i,:])\n",
    "                \n",
    "    df_f =  pd.DataFrame(FI_frac) \n",
    "    \n",
    "\n",
    "####### weighted\n",
    "\n",
    "    df_perform = pd.read_csv(path+'/model_evaluation/Summary_performance_mean.csv')\n",
    "    bacc = df_perform['Balanced Accuracy']\n",
    "\n",
    "    weight = (bacc - 0.5)/0.5\n",
    "\n",
    "    df_n_w = pd.DataFrame()\n",
    "    df_f_w = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for i in range(0,df_n.shape[0]):\n",
    "        df_n_w =  pd.concat([df_n_w,df_n.iloc[i,:] * weight[i]],axis=1)\n",
    "        df_f_w =  pd.concat([df_f_w,df_f.iloc[i,:] * weight[i]],axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    df = pd.concat([df,pd.DataFrame(df.sum()).T],axis=0)\n",
    "    df.columns=ROI_name\n",
    "    df.index=algs\n",
    "    \n",
    "    df_n = pd.concat([df_n,pd.DataFrame(df_n.sum()).T],axis=0)\n",
    "    df_n.columns=ROI_name\n",
    "    df_n.index=algs\n",
    "    \n",
    "    df_f = pd.concat([df_f,pd.DataFrame(df_f.sum()).T],axis=0)    \n",
    "    df_f.columns=ROI_name\n",
    "    df_f.index=algs   \n",
    "    \n",
    "    \n",
    "    df_n_w = pd.concat([df_n_w.T,pd.DataFrame(df_n_w.T.sum()).T],axis=0)\n",
    "    df_f_w = pd.concat([df_f_w.T,pd.DataFrame(df_f_w.T.sum()).T],axis=0)\n",
    "\n",
    "    \n",
    "    df_n_w.columns=ROI_name\n",
    "    df_n_w.index=algs\n",
    "    df_f_w.columns=ROI_name\n",
    "    df_f_w.index=algs\n",
    "    \n",
    "    return df,df_n,df_f,df_n_w,df_f_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eadd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs=['Original','WC','CR'] #no reference, whole cerebellum, composite reference region\n",
    "for r in refs:\n",
    "    path = '~/results/AV45_cnad_'+r+'/'+'AV45_ctx_cnad_'+r+'bl' # STRAMLINE output folder ('experiment name/data name')\n",
    "    print(\"ref: \",r)\n",
    "    \n",
    "    FI_p,ROI_name = readFI(path+'/model_evaluation/feature_importance/Permutation')\n",
    "\n",
    "    # Rescaled Permutation FI\n",
    "    exec('df_'+r+'_p, df_'+r+'_p_n, df_'+r+'_p_f, df_'+ r+'_p_n_w, df_'+r+'_p_f_w = rescaleFI(FI_p,ROI_name,path)')\n",
    "    # FI name: e.g. df_CR_p_n_w (normalized weighted FI)\n",
    "    \n",
    "# Top20 regions\n",
    "df_CR_p_n_w.T.sort_values(by=\"SUM\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7b990",
   "metadata": {},
   "source": [
    "# Heatmap (Fig.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4346157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "df_summary_n = pd.concat([df_Original_n,df_WC_n,df_CR_n],ignore_index = True)\n",
    "# Fraction\n",
    "df_summary_f = pd.concat([df_Original_f,df_WC_f,df_CR_f],ignore_index = True)\n",
    "\n",
    "algs_Original = []\n",
    "algs_WC = []\n",
    "algs_CR = []\n",
    "for i in range(0,algs.shape[0]):\n",
    "    algs_Original.append( \"_\".join([algs[i],'Original']))\n",
    "    algs_WC.append( \"_\".join([algs[i],'WC']))\n",
    "    algs_CR.append( \"_\".join([algs[i],'CR']))\n",
    "y_axis_labels = np.append(algs_Original,algs_WC)\n",
    "y_axis_labels = np.append(y_axis_labels,algs_CR)\n",
    "y_axis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02964974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x_axis_labels = ROI_name\n",
    "name = [\"n\",\"f\"]\n",
    "for i in range(0,2):\n",
    "    plt.figure(figsize=(35,30))\n",
    "    exec('ax = sns.heatmap(df_summary_'+name[i]+',xticklabels=x_axis_labels,yticklabels=y_axis_labels)')\n",
    "    ax.set_title('Feature Importance, Cortex only_'+str(name[i]))\n",
    "    ax.set(xlabel='Features', ylabel='Algorithms')\n",
    "    save_fig(\"Normalied Feature Importance_ctx_\"+str(name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3fa3a",
   "metadata": {},
   "source": [
    "# AD related region rank plot (Fig. 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def rank_cal(df_n,df_f,df_n_w,df_f_w,FI_type,name):\n",
    "    \n",
    "    # Claculate the rank table for each algs and rescaling methods\n",
    "    algs = np.array(['NB', 'EN', 'LR', 'DT', 'RF', 'GB', 'XGB', 'LGB', 'CGB', 'SVM', 'ANN', 'KNN', 'GP'])\n",
    "    ROIs_target = np.array(['PRECUNEUS','ISTHMUSCINGULATE','POSTERIORCINGULATE','ANTERIORCINGULATE','MEDIALORBITOFRONTAL','LATERALORBITOFRONTAL', 'ROSTRALMIDDLEFRONTAL','SUPERIORFRONTAL', 'SUPERIORPARIETAL','SUPRAMARGINAL'])\n",
    "   \n",
    "    index_id = np.append(algs,np.array(['Mean_algs','All_n','All_n_w','All_f','All_f_w']))\n",
    "    column_id = np.append(ROIs_target,np.array(['Sum']))\n",
    "    rank = pd.DataFrame(index=index_id,columns=column_id) \n",
    "\n",
    "\n",
    "    for i in range(0,len(ROIs_target)):\n",
    "        values = np.where(df_n.T.sort_values(by='SUM', ascending=False).index.str.contains(ROIs_target[i]))\n",
    "        values_w = np.where(df_n_w.T.sort_values(by='SUM', ascending=False).index.str.contains(ROIs_target[i]))\n",
    "        rank.iloc[-4,i] = values[0].mean()\n",
    "        rank.iloc[-3,i] = values_w[0].mean()\n",
    "\n",
    "        values = np.where(df_f.T.sort_values(by='SUM', ascending=False).index.str.contains(ROIs_target[i]))\n",
    "        values_w = np.where(df_f_w.T.sort_values(by='SUM', ascending=False).index.str.contains(ROIs_target[i]))\n",
    "        rank.iloc[-2,i] = values[0].mean()\n",
    "        rank.iloc[-1,i] = values_w[0].mean()\n",
    "\n",
    "        for j in range(0,df_n.shape[0]-1):\n",
    "            values_s = np.where(df_n.T.sort_values(by=algs[j], ascending=False).index.str.contains(ROIs_target[i]))\n",
    "            rank.iloc[j,i] = values_s[0].mean()\n",
    "        rank.iloc[-5,i] = round(rank.iloc[:-5,i].mean(),1)\n",
    "    rank[\"Sum\"] = round(rank.sum(axis = 1),3)\n",
    "    \n",
    "    # Plot the bar plots\n",
    "    plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "    plt.style.use('tableau-colorblind10') \n",
    "    ax=rank.iloc[:,:rank.shape[1]-1].plot(kind=\"bar\",stacked=True,cmap = cm.get_cmap('Spectral'),grid=False)#Set3\n",
    "    plt.title(FI_type+\" FI\")\n",
    "    plt.xlabel(\"Algorithms\")\n",
    "    plt.ylabel(\"FI ranking\")\n",
    "    legend = plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.3),\n",
    "               ncol=5)\n",
    "    legend.get_frame().set_alpha(None)\n",
    "    legend.get_frame().set_facecolor((0, 0, 0, 0))\n",
    "\n",
    "    for i in range(rank.shape[0]):\n",
    "        p=ax.patches[i]\n",
    "        width = p.get_width()\n",
    "        ax.annotate('{:.2f}'.format(rank.iloc[i,-1]), (p.get_x()+width/2., (rank.iloc[i,-1])+12),ha='center',\n",
    "                    va='center',fontsize=9, color='black')\n",
    "    plt.ylim([0,300])\n",
    "    plt.savefig(name, transparent=True,bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b861797",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_type = 'Permutation'\n",
    "refs=['WC','CR'] #whole cerebellum, composite reference region\n",
    "for r in refs:\n",
    "    name = '~/results/Rank_'+r+'_P.png'\n",
    "    exec('rank_p_'+r+'=rank_cal(df_'+r+'_p_n, df_'+r+'_p_f, df_'+r+'_p_n_w,df_'+r+'_p_f_w,FI_type,name)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
