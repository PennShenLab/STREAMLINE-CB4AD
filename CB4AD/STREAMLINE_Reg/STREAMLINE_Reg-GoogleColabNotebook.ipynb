{"cells":[{"cell_type":"markdown","metadata":{"id":"h47eTFUk8dzY"},"source":["# Summary"]},{"cell_type":"markdown","metadata":{"id":"BZQpJZw-8dzb"},"source":["This notebook runs all aspects of the STREAMLINE which is an automated machine learning analysis pipeline for binary classification tasks. Of note, two potentially important elements that are not automated by this pipeline include careful data cleaning and feature engineering using problem domain knowledge. Please review the README included in the associated GitHub repository for a detailed overview of how to run this pipeline. For simplicity, this notebook runs Python code outside of what is visible within it. \n","\n","This notebook is set up to run 'as-is' on a 'demo' dataset from the UCI repository (HCC dataset) using only three modeling algorithms (so that it runs in a matter of minutes). We analyze a copy of the dataset with and without covariate features to show how this pipline can be run on multiple datasets simultaneously (having the option to compare modeling on these different datasets in a later phase of the pipeline. Users will need to update pipeline run parameters below to ready the pipeline for their own needs. Suggested default run parameters suitible for most users are included, however file paths and names will need to be edited to run anything other than the 'demo' analysis. "]},{"cell_type":"markdown","metadata":{"id":"ProUmuu-8dzb"},"source":["## Google Collab and Run Enviornment Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qW5WNjL28dzc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666146930293,"user_tz":240,"elapsed":2814,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}},"outputId":"556ecdfa-2924-4f1e-9fcd-66f5dfd15b5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"SPjhJvYE8dzd","executionInfo":{"status":"ok","timestamp":1666146933490,"user_tz":240,"elapsed":3199,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["#Load all require local python files on from Google Drive\n","from google.colab import files\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ExploratoryAnalysisMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ExploratoryAnalysisJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/DataPreprocessingMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/DataPreprocessingJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/FeatureImportanceMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/FeatureImportanceJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/FeatureSelectionMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/FeatureSelectionJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ModelMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ModelJob.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/l21regjob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/StatsMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/StatsJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/DataCompareMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/DataCompareJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/PDF_ReportMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/PDF_ReportJob.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/PDF_ReportJob_Reg.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ApplyModelMain.py /content\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/ApplyModelJob.py /content\n","\n","!cp /content/drive/MyDrive/STREAMLINE-Regression/streamline/FileCleanup.py /content"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jUn9x39T8dze","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666146985278,"user_tz":240,"elapsed":51790,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}},"outputId":"2cb4b3f8-1b4e-46e2-82e6-dab0ce19a6c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: skrebate==0.7 in /usr/local/lib/python3.7/dist-packages (0.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from skrebate==0.7) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from skrebate==0.7) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from skrebate==0.7) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skrebate==0.7) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skrebate==0.7) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gplearn in /usr/local/lib/python3.7/dist-packages (0.4.2)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.0.2)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-eLCS in /usr/local/lib/python3.7/dist-packages (1.2.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scikit-eLCS) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scikit-eLCS) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scikit-eLCS) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-eLCS) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-eLCS) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->scikit-eLCS) (1.15.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-eLCS) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-eLCS) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-eLCS) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-XCS in /usr/local/lib/python3.7/dist-packages (1.0.8)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scikit-XCS) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scikit-XCS) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scikit-XCS) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-XCS) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-XCS) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->scikit-XCS) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-XCS) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-XCS) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-XCS) (1.7.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-ExSTraCS in /usr/local/lib/python3.7/dist-packages (1.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scikit-ExSTraCS) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scikit-ExSTraCS) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scikit-ExSTraCS) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-ExSTraCS) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scikit-ExSTraCS) (2022.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->scikit-ExSTraCS) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-ExSTraCS) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-ExSTraCS) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scikit-ExSTraCS) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna==2.0.0 in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (21.3)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (6.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (1.21.6)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (3.10.1)\n","Requirement already satisfied: cmaes>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (0.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (4.64.1)\n","Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (1.8.1)\n","Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (1.7.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (1.2.0)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.0.0) (1.4.41)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.0.0) (1.1.3.post0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.0.0) (4.13.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.0.0) (1.2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.0.0) (5.10.0)\n","Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (6.0)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (2.4.2)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (5.10.0)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (3.0.9)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (0.5.1)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.0.0) (3.5.1)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.0.0) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.0.0) (22.1.0)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.0.0) (1.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.0.0) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.0.0) (3.9.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.0.0) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaleido==0.0.3.post1 in /usr/local/lib/python3.7/dist-packages (0.0.3.post1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fpdf in /usr/local/lib/python3.7/dist-packages (1.7.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: group-lasso in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from group-lasso) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from group-lasso) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (1.7.3)\n"]}],"source":["#Install remaining required packages not preinstalled in Google Collab\n","!pip install skrebate==0.7\n","!pip install xgboost\n","!pip install lightgbm\n","!pip install catboost\n","!pip install gplearn\n","!pip install scikit-eLCS\n","!pip install scikit-XCS\n","!pip install scikit-ExSTraCS\n","!pip install optuna==2.0.0\n","!pip install plotly\n","!pip install kaleido==0.0.3.post1\n","!pip install fpdf\n","!pip install group-lasso"]},{"cell_type":"markdown","metadata":{"id":"HRu0j-Rg8dze"},"source":["## Notebook Housekeeping\n","Set up notebook cells to display desired results. No need to edit."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"eSfXe3qO8dzf","executionInfo":{"status":"ok","timestamp":1666146985279,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import warnings\n","import sys\n","import os\n","import shutil\n","warnings.filterwarnings('ignore')\n","\n","# Jupyter Notebook Hack: This code ensures that the results of multiple commands within a given cell are all displayed, rather than just the last. \n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""]},{"cell_type":"markdown","metadata":{"id":"laRm11sV8dzf"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## (User Specified) Run Parameters of STREAMLINE\n","These initial notebook cells include all customizable run parameters for STREAMLINE. These settings should only be left unchanged for users wishing to test out the pipeline demo (as is) to learn how it works or to confirm efficacy before running their own data. Run parameters for each phase of the pipeline are included in separate code cells of this section of the notebook.\n"]},{"cell_type":"markdown","metadata":{"id":"kGZtOKm38dzg"},"source":["### Mandatory Run Parameters for Pipeline"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MjwoF3TA8dzg","executionInfo":{"status":"ok","timestamp":1666146985279,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["demo_run = False #Leave true to run the local demo dataset (without specifying any datapaths), make False to specify a different data folder path below\n","\n","#Target dataset folder path(must include one or more .txt or .csv datasets)\n","data_path = \"/content/drive/MyDrive/STREAMLINE-Regression/Measurements/ADAS11\" # (str) Demontration Data Path Folder\n","\n","#Output foder path: where to save pipeline outputs (must be updated for a given user)\n","output_path = '/content/drive/MyDrive/STREAMLINE-Regression/Colab_Output' # (str) Demonstration Ouput Path Folder\n","\n","#Unique experiment name - folder created for this analysis within output folder path\n","experiment_name = 'ADAS11_experiment'  # (str) Demontration Experiment Name\n","\n","# Data Labels\n","class_label = 'Class' # (str) i.e. class outcome column label\n","instance_label = 'Cognition_Score' # (str) If data includes instance labels, given respective column name here, otherwise put 'None'\n","\n","#Option to manually specify feature names to leave out of analysis, or which to treat as categorical (without using built in variable type detector)\n","ignore_features = [] # list of column names (given as string values) to exclude from the analysis (only insert column names if needed, otherwise leave empty)\n","categorical_feature_headers = [] # empty list for 'auto-detect' otherwise list feature names (given as string values) to be treated as categorical. Only impacts algorithms that can take variable type into account."]},{"cell_type":"markdown","metadata":{"id":"bQ_9fYJ88dzg"},"source":["### Run Parameters for Phase 1: Exploratory Analysis"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_xgab9CQ8dzh","executionInfo":{"status":"ok","timestamp":1666146985279,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["cv_partitions = 5  # (int, > 1) Number of training/testing data partitions to create - and resulting number of models generated using each ML algorithm\n","partition_method = 'S' # (str, S R or M) for stratified, random, or matched, respectively\n","match_label = 'None' # (str) Only applies when M selected for partition-method; indicates column label with matched instance ids' \n","\n","categorical_cutoff = 10 # (int) Bumber of unique values after which a variable is considered to be quantitative vs categorical\n","sig_cutoff = 0.05 # (float, 0-1) Significance cutoff used throughout pipeline\n","export_feature_correlations = 'True' # (str, True or False) Run and export feature correlation analysis (yields correlation heatmap)\n","export_univariate_plots = 'False' # (str, True or False) Export univariate analysis plots (note: univariate analysis still output by default)\n","topFeatures = 20 # (int) Number of top features to report in notebook for univariate analysis\n","random_state = 42 # (int) Sets a specific random seed for reproducible results"]},{"cell_type":"markdown","metadata":{"id":"rAq3yrep8dzh"},"source":["### Run Parameters for Phase 2: Data Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"tq4DzpKG8dzh","executionInfo":{"status":"ok","timestamp":1666146985280,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["scale_data = 'True' # (str, True or False) Perform data scaling?\n","impute_data = 'True' # (str, True or False) Perform missing value data imputation? (required for most ML algorithms if missing data is present)\n","overwrite_cv = 'True' # (str, True or False) Overwrites earlier cv datasets with new scaled/imputed ones\n","multi_impute = 'True' # (str, True or False) Applies multivariate imputation to quantitative features, otherwise uses mean imputation"]},{"cell_type":"markdown","metadata":{"id":"OEyuMjCY8dzh"},"source":["### Run Parameters for Phase 3: Feature Importance Evaluation"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"3q5Scuj18dzi","executionInfo":{"status":"ok","timestamp":1666146985280,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["do_mutual_info = 'True' # (str, True or False) Do mutual information analysis\n","do_multisurf = 'True' # (str, True or False) Do multiSURF analysis\n","use_TURF = 'False' # (str, True or False) Use TURF wrapper around MultiSURF\n","TURF_pct = 0.5 # (float, 0.01-0.5) Proportion of instances removed in an iteration (also dictates number of iterations)\n","njobs = -1 # (int) Number of cores dedicated to running algorithm; setting to -1 will use all available cores\n","instance_subset = 2000 # (int) Sample subset size to use with multiSURF"]},{"cell_type":"markdown","metadata":{"id":"7CdYOXsk8dzi"},"source":["### Run Parameters for Phase 4: Feature Selection"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bo2JaxGl8dzi","executionInfo":{"status":"ok","timestamp":1666146985280,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["max_features_to_keep = 2000 # (int) Maximum features to keep.\n","filter_poor_features = 'False' # (str, True or False) Filter out the worst performing features prior to modeling\n","top_features = 40 # (int) Number of top features to illustrate in figures\n","export_scores = 'True' # (str, True or False) Export figure summarizing average feature importance scores over cv partitions"]},{"cell_type":"markdown","metadata":{"id":"81YkNYlA8dzi"},"source":["### Run Parameters for Phase 5: Modeling"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"cIINLJio8dzi","executionInfo":{"status":"ok","timestamp":1666146985280,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["#ML Model Algorithm Options (individual hyperparameter options can be adjusted below)\n","do_all = 'False'      # (str, True or False) indicates default value for whether all or none of the algorithms should be run\n","# Regression Algorithm\n","do_CommonReg = 'True'\n","do_linReg = 'True'\n","do_ENReg = 'True'\n","do_GL = 'True'\n","\n","# L21 Regression Series Algorithm \n","do_L21Series = 'True'\n","do_L21Reg = 'True'\n","do_L21GMMReg = 'False'\n","do_L21DGMMReg = 'False'\n","\n","# # ML Algorithms implemented by our reserach group: Rule-based ML Algorithm Options (Computationally expensive, so can be impractical to run hyperparameter sweep)\n","# do_eLCS = 'False'     # (str, True or False, or None) Run eLCS modeling (a basic supervised-learning learning classifier system)\n","# do_XCS = 'False'      # (str, True or False, or None) Run XCS modeling (a supervised-learning-only implementation of the best studied learning classifier system)\n","# do_ExSTraCS = 'None' # (str, True or False, or None) Run ExSTraCS modeling (a learning classifier system designed for biomedical data mining)\n","\n","#Other Analysis Parameters\n","training_subsample = 0  # (int) For long running algorithms, option to subsample training set (0 for no subsample) Limit Sample Size Used to train algorithms that do not scale up well in large instance spaces (i.e. XGB,SVM,KN,ANN,and LR to a lesser degree) and depending on 'instances' settings, ExSTraCS, eLCS, and XCS)\n","use_uniform_FI = 'True' # (str, True or False) Overides use of any available feature importances estimate methods from models, instead using permutation_importance uniformly\n","primary_metric = 'explained_variance' # (str) Must be an available metric identifier from (https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n","\n","#Hyperparameter Sweep Options\n","n_trials = 50   # (int or None) Number of bayesian hyperparameter optimization trials using optuna\n","timeout = 900    # (int or None) Seconds until hyperparameter sweep stops running new trials (Note: it may run longer to finish last trial started)\n","export_hyper_sweep_plots = 'True' # (str, True or False) Export hyper parameter sweep plots from optuna\n","\n","# #Learning classifier system specific options (ExSTraCS, eLCS, XCS)\n","# do_lcs_sweep = 'False' # (str, True or False) Do LCS hyperparam tuning or use below params\n","# nu = 1                 # (int, 0-10) Fixed LCS nu param\n","# iterations = 200000    # (int, > data sample size) Fixed LCS # learning iterations param\n","# N = 2000               # (int) > 500) Fixed LCS rule population maximum size param\n","# lcs_timeout = 1200     # (int) Seconds until hyperparameter sweep stops for LCS algorithms (evolutionary algorithms often require more time for a single run)"]},{"cell_type":"markdown","metadata":{"id":"K-ed_hHX8dzj"},"source":["### Hyperparameter Sweep Options for ML Algorithms\n","Users can extend or limit the range or options for given ML algorithm hyperparameters to be tested in hyperparameter optimization. These options are hardcoded when running this pipeline from the command line, but they are available here for users to see and modify. We have sought to include a broad range of relevant configurations based on online examples and relevant research publications. Use caution when modifying values below as improper modifications will lead to pipeline errors/failure. Links to available hyperparameter options for each algorithm are included below. "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"772Ljz1h8dzj","executionInfo":{"status":"ok","timestamp":1666146985281,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["def hyperparameters(random_state,feature_names):\n","    param_grid = {}\n","\n","    param_grid_L21Reg = {'lambda1':[1,100], 'max_iter': [10, 2500]}\n","\n","    param_grid_L21GMMReg = {'lambda1':[1, 300], 'lambda2':[1, 300], 'max_iter': [10, 2500]}\n","\n","    param_grid_L21DGMMReg = {'lambda1': [0.01, 100], 'lambda2': [0.01, 100], 'max_iter': [10, 2500]}\n","\n","    # Elastic Net Regressor\n","    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\n","    param_grid_EN = {'alpha':[1e-3,1],'max_iter': [10,2500],                      \n","                     'l1_ratio':[0,1],'random_state':[random_state]}\n","    # Group Lasso Regressor\n","    # https://group-lasso.readthedocs.io/en/latest/api_reference.html#\n","    param_grid_GL = {'group_reg':[1e-3,1],#'l1_reg':[0,1],\n","                     'n_iter':[10,2500],\n","                     'scale_reg': ['group_size', 'none', 'inverse_group_size'],\n","                     #'subsampling_scheme': [0.1,0.9],\n","                     #'frobenius_lipschitz': [True],\n","                     'random_state':[random_state]}\n","        \n","    #Leave code below as is...\n","    param_grid['L21Reg'] = param_grid_L21Reg\n","    param_grid['L21GMMReg'] = param_grid_L21GMMReg\n","    param_grid['L21DGMMReg'] = param_grid_L21DGMMReg\n","    param_grid['Linear Regression'] = {}\n","    param_grid['Elastic Net'] = param_grid_EN\n","    param_grid['Group Lasso'] = param_grid_GL\n","    return param_grid"]},{"cell_type":"markdown","metadata":{"id":"92DT87hB8dzl"},"source":["### Run Parameters for Phase 6:  Statistics Summary and Figure Generation"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"DNk8fE7b8dzm","executionInfo":{"status":"ok","timestamp":1666146985281,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["plot_FI_box = 'True' # (str, True or False) Plot box plot summaries comparing algorithms for each metric\n","plot_metric_boxplots = 'True' # (str, True or False) Plot feature importance boxplots for each algorithm\n","metric_weight = 'explained_variance' # (str, balanced_accuracy or roc_auc) ML model metric used as weight in composite FI plots (only supports balanced_accuracy or roc_auc as options) Recommend setting the same as primary_metric if possible.\n","top_model_features = 40  # (int) Number of top features in model to illustrate in figures"]},{"cell_type":"markdown","metadata":{"id":"q-ftT9-a8dzm"},"source":["### Run Parameters for Phase 10:  Apply Models to Replication Dataset\n","An optional phase to apply all trained models from previous phases to a separate 'replication' dataset which will be used to evaluate models across all algorithms and CV splits. In this demo, we didn't have a separate replication dataset to use for the UCI HCC dataset evaluated. Thus here we use a copy of the original HCC dataset as a 'pretend' replication dataset to demonstrate functionality. The replication data folder can include 1 or more datasets that can be evaluated as separate replication data. The user also needs to "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"05kkozJw8dzm","executionInfo":{"status":"ok","timestamp":1666146985281,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["applyToReplication = False # (Boolean, True or False) Leave false unless you have a replication dataset handy to further evaluate/compare all models in uniform manner\n","rep_data_path = \"/content/drive/MyDrive/STREAMLINE-main/DemoRepData\" # (txt) Name of folder with replication Dataset(s)\n","dataset_for_rep = \"/content/drive/MyDrive/STREAMLINE-main/DemoRepData/hcc-data_example_rep.csv\" # (txt) Path and name of dataset used to generate the models we want to apply (not the replication dataset)"]},{"cell_type":"markdown","metadata":{"id":"0ne7lHSQ8dzm"},"source":["### Run Parameters for Phase 11:  File Cleanup\n","An optional phase to delete all unnecessary/temporary files generated by the pipeline."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ayVQVBdD8dzm","executionInfo":{"status":"ok","timestamp":1666146985281,"user_tz":240,"elapsed":10,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["del_time = 'True'  # (str, True or False) Delete individual run-time files (but save summary)\n","del_oldCV = 'True' # (str, True or False) Delete any of the older versions of CV training and testing datasets not overwritten (preserves final training and testing datasets)"]},{"cell_type":"markdown","metadata":{"id":"hSLkSNWR8dzn"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 1: Exploratory Analysis"]},{"cell_type":"markdown","metadata":{"id":"SZ8rJH-48dzn"},"source":["### Identify Working Directory"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kbPBr1Ip8dzn","executionInfo":{"status":"ok","timestamp":1666146985282,"user_tz":240,"elapsed":11,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["wd_path = os.getcwd() #Working directory path automatically detected\n","wd_path = wd_path.replace('\\\\','/')\n","sys.path.insert(1, wd_path+'/streamline')"]},{"cell_type":"markdown","metadata":{"id":"q4APyCi38dzn"},"source":["### Import Python Packages"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"86WT7xUD8dzn","executionInfo":{"status":"ok","timestamp":1666146986687,"user_tz":240,"elapsed":1415,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import glob\n","import time\n","import csv\n","import pandas as pd\n","import numpy as np\n","import random\n","import pickle\n","import ExploratoryAnalysisMain\n","import ExploratoryAnalysisJob"]},{"cell_type":"markdown","metadata":{"id":"3gJBsyUr8dzn"},"source":["### Demo Setup\n","Bypasses whatever user may have entered into 'data_path' variable to ensure proper loading of local 'demo' dataset."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-ODFpc_e8dzn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666146986688,"user_tz":240,"elapsed":12,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}},"outputId":"f5bf483f-31d2-4697-e272-ca3dbfab31cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data Folder Path: /content/drive/MyDrive/STREAMLINE-Regression/Measurements/ADAS11\n"]}],"source":["if demo_run:\n","    data_path = wd_path+'/drive/MyDrive/STREAMLINE-main/DemoData'\n","print(\"Data Folder Path: \"+data_path)\n","jupyterRun = 'True' #Leave True or pipeline will not display text or figures"]},{"cell_type":"markdown","metadata":{"id":"IFPkZ75q8dzo"},"source":["### Run Exploratory Analysis"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"jP7BKhOZ8dzo","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"error","timestamp":1666146986689,"user_tz":240,"elapsed":12,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}},"outputId":"196c3204-0358-48f5-902c-5636afa87fcc"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-8bb522afd1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mExploratoryAnalysisMain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeDirTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjupyterRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/ExploratoryAnalysisMain.py\u001b[0m in \u001b[0;36mmakeDirTree\u001b[0;34m(data_path, output_path, experiment_name, jupyterRun)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Provided data_path does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: A folder with the specified experiment name already exists at \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'. This path/folder name must be unique.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Error: A folder with the specified experiment name already exists at /content/drive/MyDrive/STREAMLINE-Regression/Colab_Output/ADAS11_experiment. This path/folder name must be unique."]}],"source":["ExploratoryAnalysisMain.makeDirTree(data_path,output_path,experiment_name,jupyterRun)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_SL1-Pt8dzo","executionInfo":{"status":"aborted","timestamp":1666146986691,"user_tz":240,"elapsed":13,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["#Determine file extension of datasets in target folder:\n","file_count = 0\n","unique_datanames = []\n","for dataset_path in glob.glob(data_path+'/*'):\n","    dataset_path = str(dataset_path).replace('\\\\','/')\n","    print('---------------------------------------------------------------------------------')\n","    print(dataset_path)\n","    file_extension = dataset_path.split('/')[-1].split('.')[-1]\n","    data_name = dataset_path.split('/')[-1].split('.')[0] #Save unique dataset names so that analysis is run only once if there is both a .txt and .csv version of dataset with same name.\n","    if file_extension == 'txt' or file_extension == 'csv':\n","        if data_name not in unique_datanames:\n","            unique_datanames.append(data_name)\n","            ExploratoryAnalysisJob.runExplore(dataset_path,output_path+'/'+experiment_name,cv_partitions,partition_method,categorical_cutoff,export_feature_correlations,export_univariate_plots,class_label,instance_label,match_label,random_state,ignore_features,categorical_feature_headers,sig_cutoff,jupyterRun)\n","            file_count += 1\n","\n","if file_count == 0: #Check that there was at least 1 dataset\n","    raise Exception(\"There must be at least one .txt or .csv dataset in data_path directory\")\n","\n","#Create metadata dictionary object to keep track of pipeline run paramaters throughout phases\n","metadata = {}\n","metadata['Data Path'] = data_path\n","metadata['Output Path'] = output_path\n","metadata['Experiment Name'] = experiment_name\n","metadata['Class Label'] = class_label\n","metadata['Instance Label'] = instance_label\n","metadata['Ignored Features'] = ignore_features\n","metadata['Specified Categorical Features'] = categorical_feature_headers\n","metadata['CV Partitions'] = cv_partitions\n","metadata['Partition Method'] = partition_method\n","metadata['Match Label'] = match_label\n","metadata['Categorical Cutoff'] = categorical_cutoff\n","metadata['Statistical Significance Cutoff'] = sig_cutoff\n","metadata['Export Feature Correlations'] = export_feature_correlations\n","metadata['Export Univariate Plots'] = export_univariate_plots\n","metadata['Random Seed'] = random_state\n","metadata['Run From Jupyter Notebook'] = jupyterRun\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"]},{"cell_type":"markdown","metadata":{"id":"TJIt46p38dzq"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 2: Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"VYy-kGwo8dzq"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVZlbWWZ8dzr","executionInfo":{"status":"aborted","timestamp":1666146986691,"user_tz":240,"elapsed":13,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import DataPreprocessingJob"]},{"cell_type":"markdown","metadata":{"id":"b6x5t0B_8dzr"},"source":["### Run Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVuToWNP8dzr","executionInfo":{"status":"aborted","timestamp":1666146986692,"user_tz":240,"elapsed":14,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["dataset_paths = os.listdir(output_path+\"/\"+experiment_name)\n","dataset_paths.remove('metadata.pickle')\n","for dataset_directory_path in dataset_paths:\n","    full_path = output_path+\"/\"+experiment_name+\"/\"+dataset_directory_path\n","    print(dataset_directory_path)\n","    if dataset_directory_path != 'L21':\n","        for cv_train_path in glob.glob(full_path+\"/CVDatasets/*Train.csv\"):\n","            cv_train_path = str(cv_train_path).replace('\\\\','/')\n","            cv_test_path = cv_train_path.replace(\"Train.csv\",\"Test.csv\")\n","            DataPreprocessingJob.job(cv_train_path,cv_test_path,output_path+'/'+experiment_name,scale_data,impute_data,overwrite_cv,categorical_cutoff,class_label,instance_label,random_state,multi_impute,jupyterRun)\n","\n","\n","#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file) \n","file.close()\n","    \n","#Update metadata\n","metadata['Use Data Scaling'] = scale_data\n","metadata['Use Data Imputation'] = impute_data\n","metadata['Use Multivariate Imputation'] = multi_impute\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"]},{"cell_type":"markdown","metadata":{"id":"20HLQeHj8dzr"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 3: Feature Importance Evaluation"]},{"cell_type":"markdown","metadata":{"id":"GVPgVV2v8dzr"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlpP3ubp8dzr","executionInfo":{"status":"aborted","timestamp":1666146986692,"user_tz":240,"elapsed":13,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import FeatureImportanceJob"]},{"cell_type":"markdown","metadata":{"id":"Y6ZQpr2_8dzr"},"source":["### Run Feature Importance Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7_le_0I8dzs","executionInfo":{"status":"aborted","timestamp":1666146986692,"user_tz":240,"elapsed":13,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["dataset_paths = os.listdir(output_path+\"/\"+experiment_name)\n","removeList = removeList = ['metadata.pickle','metadata.csv','algInfo.pickle','jobsCompleted','logs','jobs','DatasetComparisons','UsefulNotebooks',experiment_name+'_ML_Pipeline_Report.pdf']\n","for text in removeList:\n","    if text in dataset_paths:\n","        dataset_paths.remove(text)\n","\n","for dataset_directory_path in dataset_paths:\n","    full_path = output_path+\"/\"+experiment_name+\"/\"+dataset_directory_path\n","    experiment_path = output_path+'/'+experiment_name\n","\n","    if eval(do_mutual_info) or eval(do_multisurf):\n","        if not os.path.exists(full_path+\"/feature_selection\"):\n","            os.mkdir(full_path+\"/feature_selection\")\n","            \n","    if eval(do_mutual_info):\n","        if not os.path.exists(full_path+\"/feature_selection/mutualinformation\"):\n","            os.mkdir(full_path+\"/feature_selection/mutualinformation\")\n","        for cv_train_path in glob.glob(full_path+\"/CVDatasets/*_CV_*Train.csv\"):\n","            cv_train_path = str(cv_train_path).replace('\\\\','/')\n","            FeatureImportanceJob.job(cv_train_path,experiment_path,random_state,class_label,instance_label,instance_subset,'mi',njobs,use_TURF,TURF_pct,jupyterRun)\n","\n","    if eval(do_multisurf):\n","        if not os.path.exists(full_path+\"/feature_selection/multisurf\"):\n","            os.mkdir(full_path+\"/feature_selection/multisurf\")\n","        for cv_train_path in glob.glob(full_path+\"/CVDatasets/*_CV_*Train.csv\"):\n","            cv_train_path = str(cv_train_path).replace('\\\\','/')\n","            FeatureImportanceJob.job(cv_train_path,experiment_path,random_state,class_label,instance_label,instance_subset,'ms',njobs,use_TURF,TURF_pct,jupyterRun)\n","\n","#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file) \n","file.close()\n","\n","#Update metadata\n","metadata['Use Mutual Information'] = do_mutual_info\n","metadata['Use MultiSURF'] = do_multisurf\n","metadata['Use TURF'] = use_TURF\n","metadata['TURF Cutoff'] = TURF_pct\n","metadata['MultiSURF Instance Subset'] = instance_subset\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkNW0Wz7diwW","executionInfo":{"status":"aborted","timestamp":1666146986693,"user_tz":240,"elapsed":14,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["if do_L21Series == 'True':\n","  path_1 = output_path + \"/\" + experiment_name\n","  os.mkdir(path_1+'/L21')\n","  for dataset_directory_path_1 in dataset_paths:\n","      dest_dir = path_1+'/L21'+'/'+dataset_directory_path_1\n","      src_dir = path_1+'/'+dataset_directory_path_1\n","      shutil.copytree(src_dir, dest_dir)"]},{"cell_type":"markdown","metadata":{"id":"AxziLxaL8dzs"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 4: Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"KZFG118c8dzs"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uq8LuYM28dzs","executionInfo":{"status":"aborted","timestamp":1666146986693,"user_tz":240,"elapsed":14,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import FeatureSelectionJob"]},{"cell_type":"markdown","metadata":{"id":"EHk7d8sa8dzs"},"source":["### Run Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PiUE_8KK8dzt","executionInfo":{"status":"aborted","timestamp":1666146986693,"user_tz":240,"elapsed":14,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["dataset_paths = os.listdir(output_path + \"/\" + experiment_name)\n","removeList = removeList = ['L21', 'metadata.pickle','metadata.csv','algInfo.pickle','jobsCompleted','logs','jobs','DatasetComparisons','UsefulNotebooks',experiment_name+'_ML_Pipeline_Report.pdf']\n","for text in removeList:\n","    if text in dataset_paths:\n","        dataset_paths.remove(text)\n","\n","for dataset_directory_path in dataset_paths:\n","    full_path = output_path + \"/\" + experiment_name + \"/\" + dataset_directory_path\n","    FeatureSelectionJob.job(full_path,do_mutual_info,do_multisurf,max_features_to_keep,filter_poor_features,top_features,export_scores,class_label,instance_label,cv_partitions,overwrite_cv,jupyterRun)\n","\n","#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file)\n","file.close()\n","\n","#Update metadata\n","metadata['Max Features to Keep'] = max_features_to_keep\n","metadata['Filter Poor Features'] = filter_poor_features\n","metadata['Top Features to Display'] = top_features\n","metadata['Export Feature Importance Plot'] = export_scores\n","metadata['Overwrite CV Datasets'] = overwrite_cv\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"]},{"cell_type":"markdown","metadata":{"id":"6Z2mquRz8dzt"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 5: ML Modeling"]},{"cell_type":"markdown","metadata":{"id":"HP2f9wxN8dzt"},"source":["### Phase 5 Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evsXRs-A8dzt","executionInfo":{"status":"aborted","timestamp":1666146986694,"user_tz":240,"elapsed":15,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import ModelJob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTMUZPCP8dzt","executionInfo":{"status":"aborted","timestamp":1666146986694,"user_tz":240,"elapsed":15,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["#Create ML modeling algorithm information dictionary, given as ['algorithm used (set to true initially by default)','algorithm abreviation', 'color used for algorithm on figures']\n","### Note that other named colors used by matplotlib can be found here: https://matplotlib.org/3.5.0/_images/sphx_glr_named_colors_003.png\n","### Make sure new ML algorithm abbreviations and color designations are unique\n","algInfo = {}\n","\n","algInfo['Linear Regression'] = [True,'Linear Regression','red']\n","algInfo['Elastic Net'] = [True, 'Elastic Net', 'steelblue']\n","algInfo['Group Lasso'] = [True, 'Group Lasso', 'orange']\n","algInfo['L21Reg'] = [True,'L21Reg','green']\n","algInfo['L21GMMReg'] = [True, 'L21GMMReg', 'darkslategray']\n","algInfo['L21DGMMReg'] = [True, 'L21DGMMReg', 'magenta']\n","### Add new algorithms here...\n","\n","\n","#Set up ML algorithm True/False use\n","if not eval(do_all): #If do all algorithms is false\n","    for key in algInfo:\n","        algInfo[key][0] = False #Set algorithm use to False\n","\n","#Set algorithm use truth for each algorithm specified by user (i.e. if user specified True/False for a specific algorithm)\n","if not do_linReg == 'None':\n","    algInfo['Linear Regression'][0] = eval(do_linReg)\n","if not do_ENReg == 'None':\n","    algInfo['Elastic Net'][0] = eval(do_ENReg)\n","if not do_GL == 'None':\n","    algInfo['Group Lasso'][0] = eval(do_GL)\n","if not do_L21Reg == 'None':\n","    algInfo['L21Reg'][0] = eval(do_L21Reg)\n","if not do_L21GMMReg == 'None':\n","    algInfo['L21GMMReg'][0] = eval(do_L21GMMReg)\n","if not do_L21DGMMReg == 'None':\n","    algInfo['L21DGMMReg'][0] = eval(do_L21DGMMReg)\n","### Add new algorithms here...\n","\n","\n","\n","#Pickle the algorithm information dictionary for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"algInfo.pickle\", 'wb')\n","pickle.dump(algInfo,pickle_out)\n","pickle_out.close()\n","\n","#Make list of algorithms to be run (full names)\n","algorithms = []\n","for key in algInfo:\n","    if algInfo[key][0]: #Algorithm is true\n","        algorithms.append(key)"]},{"cell_type":"markdown","metadata":{"id":"TKAL_ARc8dzt"},"source":["### Run ML Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkmC-G-X8dzu","scrolled":true,"executionInfo":{"status":"aborted","timestamp":1666146986694,"user_tz":240,"elapsed":15,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["dataset_paths = os.listdir(output_path + \"/\" + experiment_name)\n","removeList = removeList = ['L21', 'metadata.pickle','metadata.csv','algInfo.pickle','jobsCompleted','logs','jobs','DatasetComparisons','UsefulNotebooks',experiment_name+'_ML_Pipeline_Report.pdf']\n","for text in removeList:\n","    if text in dataset_paths:\n","        dataset_paths.remove(text)\n","print(dataset_paths)\n","if do_CommonReg == 'True':\n","  for dataset_directory_path in dataset_paths:\n","      full_path = output_path + \"/\" + experiment_name + \"/\" + dataset_directory_path\n","      if not os.path.exists(full_path+'/models'):\n","          os.mkdir(full_path+'/models')\n","      if not os.path.exists(full_path+'/model_evaluation'):\n","          os.mkdir(full_path+'/model_evaluation')\n","      if not os.path.exists(full_path+'/models/pickledModels'):\n","          os.mkdir(full_path+'/models/pickledModels')\n","\n","      for cvCount in range(cv_partitions):\n","          train_file_path = full_path+'/CVDatasets/'+dataset_directory_path+\"_CV_\"+str(cvCount)+\"_Train.csv\"\n","          test_file_path = full_path + '/CVDatasets/' + dataset_directory_path + \"_CV_\" + str(cvCount) + \"_Test.csv\"\n","          for algorithm in algorithms:\n","              if algorithm != 'L21Reg' and algorithm !='L21GMMReg' and algorithm !='L21DGMMReg':\n","                  print(algorithm)\n","                  algAbrev = algInfo[algorithm][1]\n","                  #Get header names for current CV dataset for use later in GP tree visulaization\n","                  data_name = full_path.split('/')[-1]\n","                  feature_names = pd.read_csv(full_path+'/CVDatasets/'+data_name+'_CV_'+str(cvCount)+'_Test.csv').columns.values.tolist()\n","                  if instance_label != 'None':\n","                      feature_names.remove(instance_label)\n","                  feature_names.remove(class_label)\n","                  #Get hyperparameter grid\n","                  param_grid = hyperparameters(random_state,feature_names)[algorithm]\n","                  ModelJob.runModel(algorithm,train_file_path,test_file_path,full_path,n_trials,timeout,export_hyper_sweep_plots,instance_label,class_label,random_state,cvCount,filter_poor_features,training_subsample,use_uniform_FI,primary_metric,param_grid,algAbrev)\n","\n","if do_L21Series == 'True':\n","  full_path = output_path + \"/\" + experiment_name + \"/\" + 'L21'\n","  for cvCount in range(cv_partitions):\n","      dataset_paths_2 = dataset_paths.copy()\n","      train_file_path_1 = full_path+'/'+dataset_paths[0]+'/CVDatasets/'+dataset_paths_2[0]+\"_CV_\"+str(cvCount)+\"_Train.csv\"\n","      test_file_path_1 = full_path+'/'+dataset_paths[0]+ '/CVDatasets/' + dataset_paths_2[0] + \"_CV_\" + str(cvCount) + \"_Test.csv\"\n","      train_file_path_2 = full_path+'/'+dataset_paths[1]+'/CVDatasets/'+dataset_paths_2[1]+\"_CV_\"+str(cvCount)+\"_Train.csv\"\n","      test_file_path_2 = full_path +'/'+dataset_paths[1]+ '/CVDatasets/' + dataset_paths_2[1] + \"_CV_\" + str(cvCount) + \"_Test.csv\"\n","      train_file_path_3 = full_path+'/'+dataset_paths[2]+'/CVDatasets/'+dataset_paths_2[2]+\"_CV_\"+str(cvCount)+\"_Train.csv\"\n","      test_file_path_3 = full_path +'/'+dataset_paths[2]+ '/CVDatasets/' + dataset_paths_2[2] + \"_CV_\" + str(cvCount) + \"_Test.csv\"\n","      for algorithm in algorithms:\n","        if algorithm == 'L21Reg' or algorithm =='L21GMMReg' or algorithm =='L21DGMMReg':\n","            print(algorithm)\n","            algAbrev = algInfo[algorithm][1]\n","            #Get header names for current CV dataset for use later in GP tree visulaization\n","            data_name = full_path.split('/')[-1]\n","            feature_names = pd.read_csv(full_path+'/'+dataset_paths[0]+'/CVDatasets/'+dataset_paths_2[0]+'_CV_'+str(cvCount)+'_Test.csv').columns.values.tolist()\n","            if instance_label != 'None':\n","                feature_names.remove(instance_label)\n","            feature_names.remove(class_label)\n","            #Get hyperparameter grid\n","            param_grid = hyperparameters(random_state,feature_names)[algorithm]\n","            ModelJob.runModel_2(algorithm,train_file_path_1, train_file_path_2, train_file_path_3,test_file_path_1, test_file_path_2, test_file_path_3,full_path,n_trials,timeout,export_hyper_sweep_plots,instance_label,class_label,random_state,cvCount,filter_poor_features,training_subsample,use_uniform_FI,primary_metric,param_grid,algAbrev, output_path, experiment_name)\n","\n","#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file) \n","file.close()\n","\n","#Update metadata\n","### Add new algorithms here...\n","metadata['Linear Regression'] = str(algInfo['Linear Regression'][0])\n","metadata['Elastic Net'] = str(algInfo['Elastic Net'][0])\n","metadata['Group Lasso'] = str(algInfo['Group Lasso'][0])\n","metadata['L21Reg'] = str(algInfo['L21Reg'][0])\n","metadata['L21GMMReg'] = str(algInfo['L21GMMReg'][0])\n","metadata['L21DGMMReg'] = str(algInfo['L21DGMMReg'][0])\n","\n","\n","metadata['Primary Metric'] = primary_metric\n","metadata['Training Subsample for KNN,ANN,SVM,and XGB'] = training_subsample\n","metadata['Uniform Feature Importance Estimation (Models)'] = use_uniform_FI\n","metadata['Hyperparameter Sweep Number of Trials'] = n_trials\n","metadata['Hyperparameter Sweep Number of Trials'] = n_trials\n","metadata['Hyperparameter Timeout'] = timeout\n","metadata['Export Hyperparameter Sweep Plots'] = export_hyper_sweep_plots\n","\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"]},{"cell_type":"code","source":["#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file) \n","file.close()\n","\n","#Update metadata\n","### Add new algorithms here...\n","metadata['Linear Regression'] = str(algInfo['Linear Regression'][0])\n","metadata['Elastic Net'] = str(algInfo['Elastic Net'][0])\n","metadata['Group Lasso'] = str(algInfo['Group Lasso'][0])\n","metadata['L21Reg'] = str(algInfo['L21Reg'][0])\n","metadata['L21GMMReg'] = str(algInfo['L21GMMReg'][0])\n","metadata['L21DGMMReg'] = str(algInfo['L21DGMMReg'][0])\n","\n","\n","metadata['Primary Metric'] = primary_metric\n","metadata['Training Subsample for KNN,ANN,SVM,and XGB'] = training_subsample\n","metadata['Uniform Feature Importance Estimation (Models)'] = use_uniform_FI\n","metadata['Hyperparameter Sweep Number of Trials'] = n_trials\n","metadata['Hyperparameter Sweep Number of Trials'] = n_trials\n","metadata['Hyperparameter Timeout'] = timeout\n","metadata['Export Hyperparameter Sweep Plots'] = export_hyper_sweep_plots\n","\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()"],"metadata":{"id":"2_UXofjC0UdD","executionInfo":{"status":"aborted","timestamp":1666146986695,"user_tz":240,"elapsed":16,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wH3spCnU8dzu"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 6: Statistics (Stats Summaries, Figures, Statistical Comparisons)"]},{"cell_type":"markdown","metadata":{"id":"rORNdZ3n8dzu"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52JPBP0W8dzu","executionInfo":{"status":"aborted","timestamp":1666146986695,"user_tz":240,"elapsed":15,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import StatsJob"]},{"cell_type":"markdown","metadata":{"id":"POVmBAuE8dzu"},"source":["### Run Statistics Summary and Figure Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13jEzsWH8dzu","scrolled":true,"executionInfo":{"status":"aborted","timestamp":1666146986695,"user_tz":240,"elapsed":15,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["#Unpickle metadata from previous phase\n","file = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'rb')\n","metadata = pickle.load(file)\n","file.close()\n","metadata['Export Metric Boxplots'] = plot_metric_boxplots\n","metadata['Export Feature Importance Boxplots'] = plot_FI_box\n","metadata['Metric Weighting Composite FI Plots'] = metric_weight\n","metadata['Top Model Features To Display'] = top_model_features\n","#Pickle the metadata for future use\n","pickle_out = open(output_path+'/'+experiment_name+'/'+\"metadata.pickle\", 'wb')\n","pickle.dump(metadata,pickle_out)\n","pickle_out.close()\n","\n","#Now that primary pipeline phases are complete generate a human readable version of metadata\n","df = pd.DataFrame.from_dict(metadata, orient ='index')\n","df.to_csv(output_path+'/'+experiment_name+'/'+'metadata.csv',index=True)\n","\n","# Iterate through datasets\n","dataset_paths = os.listdir(output_path + \"/\" + experiment_name)\n","removeList = removeList = ['metadata.pickle','metadata.csv','algInfo.pickle','jobsCompleted','logs','jobs','DatasetComparisons','UsefulNotebooks',experiment_name+'_ML_Pipeline_Report.pdf']\n","for text in removeList:\n","    if text in dataset_paths:\n","        dataset_paths.remove(text)\n","for dataset_directory_path in dataset_paths:\n","    if dataset_directory_path != 'L21':\n","        full_path = output_path + \"/\" + experiment_name + \"/\" + dataset_directory_path\n","        StatsJob.job_reg(full_path,plot_FI_box,class_label,instance_label,cv_partitions,scale_data,plot_metric_boxplots,primary_metric,top_model_features,sig_cutoff,metric_weight,jupyterRun)\n","        "]},{"cell_type":"markdown","metadata":{"id":"7maM_tZ68dzu"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 7: Dataset Comparison (Optional: Use only if > 1 dataset was analyzed)"]},{"cell_type":"markdown","metadata":{"id":"vxvVpqQT8dzv"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENiuJTHr8dzv","executionInfo":{"status":"aborted","timestamp":1666146986696,"user_tz":240,"elapsed":16,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import DataCompareJob"]},{"cell_type":"markdown","metadata":{"id":"1LzGjuz_8dzv"},"source":["### Run Dataset Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F74vgxAi8dzv","executionInfo":{"status":"aborted","timestamp":1666146986696,"user_tz":240,"elapsed":16,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["if do_L21Series == 'True':\n","    dataset_paths.remove('L21')\n","if len(dataset_paths) > 1:\n","    DataCompareJob.job(output_path+'/'+experiment_name,sig_cutoff,jupyterRun)"]},{"cell_type":"markdown","metadata":{"id":"9ym5UNON8dzv"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 8: PDF Training Report Generator (Optional)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"apShjsZ3ZO1b","executionInfo":{"status":"ok","timestamp":1666147015135,"user_tz":240,"elapsed":316,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import PDF_ReportJob_Reg"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"uIZwGqGtZR6O","executionInfo":{"status":"ok","timestamp":1666147048312,"user_tz":240,"elapsed":32705,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c0cae9d-30a8-4bb6-8fb4-c27e6844f796"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-19 02:36:55.283135\n","Starting Report\n","['Data Path:', '/content/drive/MyDrive/STREAMLINE-Regression/Measurements/ADAS11', '\\n', 'Output Path:', '/content/drive/MyDrive/STREAMLINE-Regression/Colab_Output', '\\n', 'Experiment Name:', 'ADAS11_experiment', '\\n', 'Class Label:', 'Class', '\\n', 'Instance Label:', 'Cognition_Score', '\\n', 'Ignored Features:', '[]', '\\n', 'Specified Categorical Features:', '[]', '\\n', 'CV Partitions:', '5', '\\n', 'Partition Method:', 'S', '\\n', 'Match Label:', 'None', '\\n', 'Categorical Cutoff:', '10', '\\n', 'Statistical Significance Cutoff:', '0.05', '\\n', 'Export Feature Correlations:', 'True', '\\n', 'Export Univariate Plots:', 'False', '\\n', 'Random Seed:', '42', '\\n', 'Run From Jupyter Notebook:', 'True', '\\n', 'Use Data Scaling:', 'True', '\\n', 'Use Data Imputation:', 'True', '\\n', 'Use Multivariate Imputation:', 'True', '\\n', 'Use Mutual Information:', 'True', '\\n', 'Use MultiSURF:', 'True', '\\n', 'Use TURF:', 'False', '\\n', 'TURF Cutoff:', '0.5', '\\n', 'MultiSURF Instance Subset:', '2000', '\\n', 'Max Features to Keep:', '2000', '\\n', 'Filter Poor Features:', 'False', '\\n', 'Top Features to Display:', '40', '\\n', 'Export Feature Importance Plot:', 'True', '\\n', 'Overwrite CV Datasets:', 'True', '\\n', 'Linear Regression:', 'True', '\\n', 'Elastic Net:', 'True', '\\n', 'Group Lasso:', 'True', '\\n', 'L21Reg:', 'True', '\\n', 'L21GMMReg:', 'False', '\\n', 'L21DGMMReg:', 'False', '\\n', 'Primary Metric:', 'explained_variance', '\\n', 'Training Subsample for KNN,ANN,SVM,and XGB:', '0', '\\n', 'Uniform Feature Importance Estimation (Models):', 'True', '\\n', 'Hyperparameter Sweep Number of Trials:', '50', '\\n', 'Hyperparameter Timeout:', '900', '\\n', 'Export Hyperparameter Sweep Plots:', 'True', '\\n', 'Export Metric Boxplots:', 'True', '\\n', 'Export Feature Importance Boxplots:', 'True', '\\n', 'Metric Weighting Composite FI Plots:', 'explained_variance', '\\n', 'Top Model Features To Display:', '40', '\\n']\n","Publishing Univariate Analysis\n","Publishing Model Prediction Summary\n","['av45_ADAS11', 'fdg_ADAS11', 'vbm_ADAS11']\n","Publishing Average Model Prediction Statistics\n","Publishing Feature Importance Summaries\n","Publishing Dataset Comparison Boxplots\n","Publishing Statistical Analysis\n","Publishing Runtime Summary\n","Phase 8 complete\n"]}],"source":["experiment_path = output_path+'/'+experiment_name\n","PDF_ReportJob_Reg.job(experiment_path,'True','None','None')"]},{"cell_type":"markdown","metadata":{"id":"L1itH5nZ8dzv"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 9: Apply Models to Replication Data (Optional)"]},{"cell_type":"markdown","metadata":{"id":"WmCSgeNS8dzw"},"source":["### Import Additional Python Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjfHE3rT8dzw","executionInfo":{"status":"aborted","timestamp":1666146986697,"user_tz":240,"elapsed":17,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import ApplyModelJob"]},{"cell_type":"markdown","metadata":{"id":"a4_lLLea8dzw"},"source":["### Specify Run Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Fc3nUse8dzw","executionInfo":{"status":"aborted","timestamp":1666146986697,"user_tz":240,"elapsed":17,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["if demo_run:\n","    rep_data_path = wd_path+'/drive/MyDrive/STREAMLINE-main/DemoRepData'\n","print(\"Replication Data Folder Path: \"+rep_data_path)\n","print(\"Dataset Path: \"+dataset_for_rep)"]},{"cell_type":"markdown","metadata":{"id":"yn4BqG7E8dzw"},"source":["### Run Application of Models to Replication Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oa9-vewM8dzw","executionInfo":{"status":"aborted","timestamp":1666146986698,"user_tz":240,"elapsed":18,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["if applyToReplication:\n","    data_name = dataset_for_rep.split('/')[-1].split('.')[0] #Save unique dataset names so that analysis is run only once if there is both a .txt and .csv version of dataset with same name.\n","    full_path = output_path + \"/\" + experiment_name + \"/\" + data_name #location of folder containing models respective training dataset\n","    full_path\n","    # full_path_2 = output_path + \"/\" + experiment_name + \"/\" + data_name\n","    if not os.path.exists(full_path):\n","        os.mkdir(full_path)\n","    if not os.path.exists(full_path+\"/applymodel\"):\n","        os.mkdir(full_path+\"/applymodel\")\n","\n","    #Determine file extension of datasets in target folder:\n","    file_count = 0\n","    unique_datanames = []\n","    for datasetFilename in glob.glob(rep_data_path+'/*'):\n","        datasetFilename = str(datasetFilename).replace('\\\\','/')\n","\n","        file_extension = datasetFilename.split('/')[-1].split('.')[-1]\n","        apply_name = datasetFilename.split('/')[-1].split('.')[0] #Save unique dataset names so that analysis is run only once if there is both a .txt and .csv version of dataset with same name.\n","        if not os.path.exists(full_path+\"/applymodel/\"+apply_name):\n","            os.mkdir(full_path+\"/applymodel/\"+apply_name)\n","\n","        if file_extension == 'txt' or file_extension == 'csv':\n","            if apply_name not in unique_datanames:\n","                unique_datanames.append(apply_name)\n","                ApplyModelJob.job(datasetFilename,full_path,class_label,instance_label,categorical_cutoff,sig_cutoff,cv_partitions,scale_data,impute_data,primary_metric,dataset_for_rep,match_label,plot_ROC,plot_PRC,plot_metric_boxplots,export_feature_correlations,jupyterRun,multi_impute)\n","                file_count += 1\n","\n","    if file_count == 0: #Check that there was at least 1 dataset\n","        raise Exception(\"There must be at least one .txt or .csv dataset in rep_data_path directory\")"]},{"cell_type":"markdown","metadata":{"id":"_JLQNC5h8dzw"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 10: PDF Apply Report Generator (Optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhQNBsBX8dzx","executionInfo":{"status":"aborted","timestamp":1666146986698,"user_tz":240,"elapsed":18,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["import PDF_ReportJob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1E5e4AIt8dzx","executionInfo":{"status":"aborted","timestamp":1666146986698,"user_tz":240,"elapsed":18,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["if applyToReplication:\n","    experiment_path = output_path+'/'+experiment_name\n","    PDF_ReportJob.job(experiment_path,'False',rep_data_path,dataset_for_rep)"]},{"cell_type":"markdown","metadata":{"id":"RT80Ky968dzx"},"source":["## -----------------------------------------------------------------------------------------------------------------\n","## Phase 11: File Cleanup (Optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnpxRcR28dzx","executionInfo":{"status":"aborted","timestamp":1666146986699,"user_tz":240,"elapsed":19,"user":{"displayName":"Yanbo Feng","userId":"17225910291528625753"}}},"outputs":[],"source":["# Get dataset paths for all completed dataset analyses in experiment folder\n","datasets = os.listdir(experiment_path)\n","experiment_name = experiment_path.split('/')[-1] #Name of experiment folder\n","removeList = removeList = ['metadata.pickle','metadata.csv','algInfo.pickle','jobsCompleted','logs','jobs','DatasetComparisons','UsefulNotebooks',experiment_name+'_ML_Pipeline_Report.pdf']\n","for text in removeList:\n","    if text in datasets:\n","        datasets.remove(text)\n","\n","#Delete jobscompleted folder/files\n","try:\n","    shutil.rmtree(experiment_path+'/'+'jobsCompleted')\n","except:\n","    pass\n","\n","#Delete target files within each dataset subfolder\n","for dataset in datasets:\n","    #Delete individual runtime files (save runtime summary generated in phase 6)\n","    if eval(del_time):\n","        try:\n","            shutil.rmtree(experiment_path+'/'+dataset+'/'+'runtime')\n","            print(\"Individual Runtime Files Deleted\")\n","        except:\n","            pass\n","    #Delete temporary feature importance pickle files (only needed for phase 4 and then saved as summary files in phase 6)\n","    try:\n","        shutil.rmtree(experiment_path+'/'+dataset+'/feature_selection/mutualinformation/pickledForPhase4')\n","        print(\"Mutual Information Pickle Files Deleted\")\n","    except:\n","        pass\n","    try:\n","        shutil.rmtree(experiment_path+'/'+dataset+'/feature_selection/multisurf/pickledForPhase4')\n","        print(\"MultiSURF Pickle Files Deleted\")\n","    except:\n","        pass\n","    #Delete older training and testing CV datasets (does not delete any final versions used for training). Older cv datasets might have been kept to see what they look like prior to preprocessing and feature selection.\n","    if eval(del_oldCV):\n","        #Delete CV files generated after preprocessing but before feature selection\n","        files = glob.glob(experiment_path+'/'+dataset+'/CVDatasets/*CVOnly*')\n","        for f in files:\n","            try:\n","                os.remove(f)\n","                print(\"Deleted Intermediary CV-Only Dataset Files\")\n","            except:\n","                pass\n","        #Delete CV files generated after CV partitioning but before preprocessing\n","        files = glob.glob(experiment_path+'/'+dataset+'/CVDatasets/*CVPre*')\n","        for f in files:\n","            try:\n","                os.remove(f)\n","                print(\"Deleted Intermediary CV-Pre Dataset Files\")\n","            except:\n","                pass"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}